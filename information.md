我需要你帮我做一个精美英文网页，来展示我的论文，这是一个论文的主页。
首先论文的标题是：
\underline{SVOO}: Training-Free \underline{S}parse Attention for Fast \underline{V}ideo Generation via\\ \underline{O}ffline Layer-Wise Sparsity Profiling and \underline{O}nline Bidirectional Co-Clustering

然后论文的abstract是
Diffusion Transformers (DiTs) achieve strong video generation quality but suffer from high inference cost due to dense 3D attention, leading to the development of sparse attention technologies to improve efficiency.
However, existing training-free sparse attention methods in video generation still face two unresolved limitations: \textit{ignoring layer heterogeneity in attention pruning} and \textit{ignoring query-key coupling in block partitioning}, which hinder a better quality-speedup trade-off.
In this work, we uncover a critical insight that \textit{the attention sparsity of each layer is its intrinsic property, with minor effects across different inputs}.
Motivated by this, we propose \textbf{\underline{SVOO}}, a training-free \textbf{\underline{S}}parse attention framework for fast \textbf{\underline{V}}ideo generation via
\textbf{\underline{O}}ffline layer-wise sparsity profiling and \textbf{\underline{O}}nline bidirectional co-clustering. 
Specifically, SVOO\ adopts a two-stage paradigm: (i) offline layer-wise sensitivity profiling to derive intrinsic per-layer pruning levels, and (ii) online block-wise sparse attention via a novel bidirectional co-clustering algorithm.
Extensive experiments on seven widely used video generation models demonstrate that SVOO\ achieves a superior quality-speedup trade-off over state-of-the-art methods, delivering up to 
$1.93\times$ speedup while maintaining a PSNR of up to 29 dB on Wan2.1.

* index.html在/data/chenjiayu/jiayi_luo/SparseAttention/luojy/jiayi-sparse-attention/reference/website/index.html

# 第一个section是：SVOO achieves better quality-efficiency tradeoff
然后我的模型包括：Dense Attenion, SVG1, SVG2, SVOO
(1) Wan2.1-1.3B-T2V
(2) Wan2.1-14B-T2V
(3) Wan2.2-14B-T2V
(4) HunyuanVideo-T2V
放以上模型的对比视频，视频路径在
/data/chenjiayu/jiayi_luo/SparseAttention/luojy/jiayi-sparse-attention/reference/website/videos
其中SVOO是我们的方法，可以特别框起来，同时Dense也可以框起来。


帮我写上生成的时间
(1) Wan2.1-1.3B-T2V
Dense Attention:418s
SVG1:261s
SVG2:238s
SVOO:213s

(2) Wan2.1-14B-T2V
Dense Attention:1983s
SVG1:1241s
SVG2:1264s
SVOO:1200s

(3) Wan2.2-14B-T2V
Dense Attention:1608s
SVG1:1047s
SVG2:1061s
SVOO:988s


(4) HunyuanVideo-T2V
Dense Attention:1780s
SVG1:899s
SVG2:912s
SVOO:825s


(5) Wan2.1-14B-I2V
Dense Attention:1660s
SVG1:1051s
SVG2:11000s
SVOO:958s

(6) Wan2.2-14B-I2V
Dense Attention:1608s
SVG1:1031s
SVG2:1057s
SVOO:992s


(7) HunyuanVideo-I2V
Dense Attention:1759s
SVG1:889s
SVG2:888s
SVOO:812s


# 第二个section是：More examples generated by SVOO
然后放一些examples：
视频路径在
/data/chenjiayu/jiayi_luo/SparseAttention/luojy/jiayi-sparse-attention/reference/website/examples


# 第三个section是：More examples generated by SVOO